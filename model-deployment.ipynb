{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Verify GPU Availability\n",
    "available = torch.cuda.is_available()\n",
    "print(available)  # Returns True if GPU is available\n",
    "if available:\n",
    "\tprint(torch.cuda.get_device_name(0))  # Check GPU model name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Classification\n",
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    reviews_df = pd.read_csv(\"car_reviews.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"The file 'car_reviews.csv' was not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Review'], dtype='object')\n",
      "                                                 Review\n",
      "0     Bought 2017 Optima Hybrid in November 17. It w...\n",
      "1      You get a lot for your money and great perfor...\n",
      "2      This car is amazing and have no complaints. Y...\n",
      "3     At 11k now in a lease for 39 months and it onl...\n",
      "4     I've owned BMW, Lexus, Mercedes-Benz in the la...\n",
      "...                                                 ...\n",
      "5954  Kia did a great job with this all new car, buy...\n",
      "5955   When purchasing the car, I read that the newl...\n",
      "5956  The new designed Kia Rio is awesome. Much room...\n",
      "5957  Everyone seems so hyped on having the latest &...\n",
      "5958   Kia Rio is an excellent car to drive, it's co...\n",
      "\n",
      "[5959 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df.columns)\n",
    "print(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "reviews_df.columns = reviews_df.columns.str.strip().str.lower()\n",
    "print(reviews_df.columns)\n",
    "reviews = reviews_df['review'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the zero-shot-classification pipeline and Define categories\n",
    "\n",
    "Note: This model is with 406 million parameters. It is very slow when running on the CPU. So we run the classification on the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 0 if available else -1  # 0 for GPU, -1 for CPU\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "    \n",
    "print(classifier.device.type)\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    \"talks about driving experience\",\n",
    "    \"talks about features\",\n",
    "    \"talks about value for money\",\n",
    "    \"talks about issues\",\n",
    "    \"other\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the classificaion to each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine batch size dynamically (Example: 32 reviews per batch if on GPU)\n",
    "if device == 0:  # GPU available\n",
    "    batch_size = min(len(reviews), 2048)  # Use up to 2048 reviews per batch for GPU\n",
    "else:  # CPU\n",
    "    batch_size = min(len(reviews), 128)  # Limit batch size for CPU\n",
    "\n",
    "# Function to process a single batch\n",
    "def process_batch(batch):\n",
    "    return classifier(batch, candidate_labels=categories)\n",
    "\n",
    "# Process the reviews in parallel batches\n",
    "results = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for i in range(0, len(reviews), batch_size):\n",
    "        batch = reviews[i:i + batch_size]\n",
    "        # Submit each batch to the thread pool\n",
    "        future = executor.submit(process_batch, batch)\n",
    "        # Extend results with the output\n",
    "        results.extend(future.result())\n",
    "\n",
    "# Extract the top category for each review\n",
    "reviews_df['talks_about'] = [result['labels'][0] for result in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load the setiment analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df84d5273f76411b9d913cf4fc3e1b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shaveen Udayanga\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shaveen Udayanga\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8f7b55083d4b559b2f201a258b526b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cd8a73dabe46f58abcec802ceedfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a72cb14c4f14946b8500d077a13a920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1\n",
    "sentiment_classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle reviews longer than 512 tokens use truncate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze sentiment with truncation\n",
    "def analyze_sentiment(batch):\n",
    "    return sentiment_classifier(batch, truncation=True)\n",
    "\n",
    "# Convert reviews to a list\n",
    "reviews = reviews_df['review'].tolist()\n",
    "\n",
    "# Process reviews in batches\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "batch_size = 128 if device == -1 else 512  # Adjust batch size based on system capacity\n",
    "sentiments = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for i in range(0, len(reviews), batch_size):\n",
    "        batch = reviews[i:i + batch_size]\n",
    "        future = executor.submit(analyze_sentiment, batch)\n",
    "        sentiments.extend(future.result())\n",
    "\n",
    "# Add sentiment labels to the DataFrame\n",
    "reviews_df['sentiment'] = [result['label'] for result in sentiments]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the classified reviews to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv('classified_sentiment_reviews.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
